{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers by HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>length</th>\n",
       "      <th>charge</th>\n",
       "      <th>chargedensity</th>\n",
       "      <th>formulaC</th>\n",
       "      <th>formulaH</th>\n",
       "      <th>formulaN</th>\n",
       "      <th>formulaO</th>\n",
       "      <th>formulaS</th>\n",
       "      <th>...</th>\n",
       "      <th>_HydrophobicityD2001</th>\n",
       "      <th>_HydrophobicityD2025</th>\n",
       "      <th>_HydrophobicityD2050</th>\n",
       "      <th>_HydrophobicityD2075</th>\n",
       "      <th>_HydrophobicityD2100</th>\n",
       "      <th>_HydrophobicityD3001</th>\n",
       "      <th>_HydrophobicityD3025</th>\n",
       "      <th>_HydrophobicityD3050</th>\n",
       "      <th>_HydrophobicityD3075</th>\n",
       "      <th>_HydrophobicityD3100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O00141</td>\n",
       "      <td>MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...</td>\n",
       "      <td>431.0</td>\n",
       "      <td>6.168</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>2211</td>\n",
       "      <td>3416</td>\n",
       "      <td>574</td>\n",
       "      <td>640</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266</td>\n",
       "      <td>58.861</td>\n",
       "      <td>136.076</td>\n",
       "      <td>204.430</td>\n",
       "      <td>271.519</td>\n",
       "      <td>0.730</td>\n",
       "      <td>83.212</td>\n",
       "      <td>155.474</td>\n",
       "      <td>229.197</td>\n",
       "      <td>314.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O14920</td>\n",
       "      <td>MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-14.843</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>3733</td>\n",
       "      <td>5900</td>\n",
       "      <td>1008</td>\n",
       "      <td>1224</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>79.736</td>\n",
       "      <td>151.982</td>\n",
       "      <td>245.815</td>\n",
       "      <td>333.040</td>\n",
       "      <td>0.410</td>\n",
       "      <td>75.000</td>\n",
       "      <td>148.361</td>\n",
       "      <td>221.311</td>\n",
       "      <td>308.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O15111</td>\n",
       "      <td>MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...</td>\n",
       "      <td>745.0</td>\n",
       "      <td>-8.616</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>3714</td>\n",
       "      <td>5853</td>\n",
       "      <td>985</td>\n",
       "      <td>1149</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606</td>\n",
       "      <td>79.920</td>\n",
       "      <td>153.414</td>\n",
       "      <td>230.120</td>\n",
       "      <td>298.795</td>\n",
       "      <td>0.394</td>\n",
       "      <td>70.079</td>\n",
       "      <td>134.252</td>\n",
       "      <td>212.992</td>\n",
       "      <td>292.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P00533</td>\n",
       "      <td>MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>-12.897</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>5826</td>\n",
       "      <td>9137</td>\n",
       "      <td>1597</td>\n",
       "      <td>1835</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>69.799</td>\n",
       "      <td>140.268</td>\n",
       "      <td>210.291</td>\n",
       "      <td>270.694</td>\n",
       "      <td>0.260</td>\n",
       "      <td>76.042</td>\n",
       "      <td>153.906</td>\n",
       "      <td>222.135</td>\n",
       "      <td>314.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P04626</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>-32.426</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>6004</td>\n",
       "      <td>9333</td>\n",
       "      <td>1633</td>\n",
       "      <td>1880</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795</td>\n",
       "      <td>61.630</td>\n",
       "      <td>127.435</td>\n",
       "      <td>205.368</td>\n",
       "      <td>249.304</td>\n",
       "      <td>0.252</td>\n",
       "      <td>74.559</td>\n",
       "      <td>149.874</td>\n",
       "      <td>216.877</td>\n",
       "      <td>316.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>P42345</td>\n",
       "      <td>MLGTGPAAATTAATTSSNVSVLQQFASGLKSRNEETRAKAAKELQH...</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>-7.013</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>12731</td>\n",
       "      <td>20074</td>\n",
       "      <td>3428</td>\n",
       "      <td>3862</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339</td>\n",
       "      <td>68.510</td>\n",
       "      <td>144.018</td>\n",
       "      <td>212.528</td>\n",
       "      <td>287.472</td>\n",
       "      <td>0.116</td>\n",
       "      <td>76.505</td>\n",
       "      <td>138.889</td>\n",
       "      <td>222.106</td>\n",
       "      <td>295.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Q9BUB5</td>\n",
       "      <td>MVSSQKLEKPIEMGSSEPLPIADGDRRRKKKRRGRATDSLPGKFED...</td>\n",
       "      <td>465.0</td>\n",
       "      <td>-3.844</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>2227</td>\n",
       "      <td>3519</td>\n",
       "      <td>613</td>\n",
       "      <td>716</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.676</td>\n",
       "      <td>74.860</td>\n",
       "      <td>126.816</td>\n",
       "      <td>193.855</td>\n",
       "      <td>259.218</td>\n",
       "      <td>0.758</td>\n",
       "      <td>93.182</td>\n",
       "      <td>181.061</td>\n",
       "      <td>248.485</td>\n",
       "      <td>352.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>P49759</td>\n",
       "      <td>MRHSKRTYCPDWDDKDWDYGKWRSSSSHKRRKRSHSSAQENKRCKY...</td>\n",
       "      <td>484.0</td>\n",
       "      <td>16.713</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>2503</td>\n",
       "      <td>3859</td>\n",
       "      <td>747</td>\n",
       "      <td>750</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.685</td>\n",
       "      <td>58.989</td>\n",
       "      <td>120.787</td>\n",
       "      <td>193.258</td>\n",
       "      <td>271.348</td>\n",
       "      <td>0.775</td>\n",
       "      <td>151.938</td>\n",
       "      <td>215.504</td>\n",
       "      <td>293.023</td>\n",
       "      <td>375.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Q9UBF8</td>\n",
       "      <td>MGDTVVEPAPLKPTSEPTSGPPGNNGGSLLSVITEGVGELSVIDPE...</td>\n",
       "      <td>816.0</td>\n",
       "      <td>-14.527</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>3983</td>\n",
       "      <td>6286</td>\n",
       "      <td>1086</td>\n",
       "      <td>1277</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678</td>\n",
       "      <td>66.441</td>\n",
       "      <td>126.102</td>\n",
       "      <td>200.678</td>\n",
       "      <td>275.932</td>\n",
       "      <td>0.394</td>\n",
       "      <td>81.890</td>\n",
       "      <td>180.709</td>\n",
       "      <td>257.087</td>\n",
       "      <td>321.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Q16512</td>\n",
       "      <td>MASDAVQSEPRSWSLLEQLGLAGADLAAPGVQQQLELERERLRREI...</td>\n",
       "      <td>942.0</td>\n",
       "      <td>-10.152</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>4539</td>\n",
       "      <td>7213</td>\n",
       "      <td>1275</td>\n",
       "      <td>1432</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548</td>\n",
       "      <td>68.219</td>\n",
       "      <td>129.315</td>\n",
       "      <td>190.959</td>\n",
       "      <td>257.808</td>\n",
       "      <td>0.368</td>\n",
       "      <td>97.794</td>\n",
       "      <td>186.765</td>\n",
       "      <td>266.912</td>\n",
       "      <td>346.324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows Ã— 664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target_ID                                             Target  length  \\\n",
       "0      O00141  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...   431.0   \n",
       "1      O14920  MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...   756.0   \n",
       "2      O15111  MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...   745.0   \n",
       "3      P00533  MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...  1210.0   \n",
       "4      P04626  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...  1255.0   \n",
       "..        ...                                                ...     ...   \n",
       "224    P42345  MLGTGPAAATTAATTSSNVSVLQQFASGLKSRNEETRAKAAKELQH...  2549.0   \n",
       "225    Q9BUB5  MVSSQKLEKPIEMGSSEPLPIADGDRRRKKKRRGRATDSLPGKFED...   465.0   \n",
       "226    P49759  MRHSKRTYCPDWDDKDWDYGKWRSSSSHKRRKRSHSSAQENKRCKY...   484.0   \n",
       "227    Q9UBF8  MGDTVVEPAPLKPTSEPTSGPPGNNGGSLLSVITEGVGELSVIDPE...   816.0   \n",
       "228    Q16512  MASDAVQSEPRSWSLLEQLGLAGADLAAPGVQQQLELERERLRREI...   942.0   \n",
       "\n",
       "     charge  chargedensity  formulaC  formulaH  formulaN  formulaO  formulaS  \\\n",
       "0     6.168       0.000126      2211      3416       574       640        15   \n",
       "1   -14.843      -0.000171      3733      5900      1008      1224        40   \n",
       "2    -8.616      -0.000102      3714      5853       985      1149        45   \n",
       "3   -12.897      -0.000096      5826      9137      1597      1835        85   \n",
       "4   -32.426      -0.000235      6004      9333      1633      1880        82   \n",
       "..      ...            ...       ...       ...       ...       ...       ...   \n",
       "224  -7.013      -0.000024     12731     20074      3428      3862       130   \n",
       "225  -3.844      -0.000075      2227      3519       613       716        22   \n",
       "226  16.713       0.000292      2503      3859       747       750        22   \n",
       "227 -14.527      -0.000159      3983      6286      1086      1277        32   \n",
       "228 -10.152      -0.000098      4539      7213      1275      1432        27   \n",
       "\n",
       "     ...  _HydrophobicityD2001  _HydrophobicityD2025  _HydrophobicityD2050  \\\n",
       "0    ...                 1.266                58.861               136.076   \n",
       "1    ...                 0.881                79.736               151.982   \n",
       "2    ...                 1.606                79.920               153.414   \n",
       "3    ...                 0.671                69.799               140.268   \n",
       "4    ...                 0.795                61.630               127.435   \n",
       "..   ...                   ...                   ...                   ...   \n",
       "224  ...                 0.339                68.510               144.018   \n",
       "225  ...                 1.676                74.860               126.816   \n",
       "226  ...                 1.685                58.989               120.787   \n",
       "227  ...                 0.678                66.441               126.102   \n",
       "228  ...                 0.548                68.219               129.315   \n",
       "\n",
       "     _HydrophobicityD2075  _HydrophobicityD2100  _HydrophobicityD3001  \\\n",
       "0                 204.430               271.519                 0.730   \n",
       "1                 245.815               333.040                 0.410   \n",
       "2                 230.120               298.795                 0.394   \n",
       "3                 210.291               270.694                 0.260   \n",
       "4                 205.368               249.304                 0.252   \n",
       "..                    ...                   ...                   ...   \n",
       "224               212.528               287.472                 0.116   \n",
       "225               193.855               259.218                 0.758   \n",
       "226               193.258               271.348                 0.775   \n",
       "227               200.678               275.932                 0.394   \n",
       "228               190.959               257.808                 0.368   \n",
       "\n",
       "     _HydrophobicityD3025  _HydrophobicityD3050  _HydrophobicityD3075  \\\n",
       "0                  83.212               155.474               229.197   \n",
       "1                  75.000               148.361               221.311   \n",
       "2                  70.079               134.252               212.992   \n",
       "3                  76.042               153.906               222.135   \n",
       "4                  74.559               149.874               216.877   \n",
       "..                    ...                   ...                   ...   \n",
       "224                76.505               138.889               222.106   \n",
       "225                93.182               181.061               248.485   \n",
       "226               151.938               215.504               293.023   \n",
       "227                81.890               180.709               257.087   \n",
       "228                97.794               186.765               266.912   \n",
       "\n",
       "     _HydrophobicityD3100  \n",
       "0                 314.599  \n",
       "1                 308.197  \n",
       "2                 292.520  \n",
       "3                 314.583  \n",
       "4                 316.121  \n",
       "..                    ...  \n",
       "224               295.023  \n",
       "225               352.273  \n",
       "226               375.194  \n",
       "227               321.260  \n",
       "228               346.324  \n",
       "\n",
       "[229 rows x 664 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "protein_descriptors = pd.read_csv(r'C:\\Users\\gonca\\Documents\\GitHub\\SIB_Work/protein_descriptors.csv')\n",
    "protein_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProtBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Rostlab/prot_bert_bfd\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "protein_sequences = protein_descriptors['Target'].tolist()\n",
    "tokenized_sequences = tokenizer(protein_sequences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_sequences)\n",
    "    embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([229, 3, 1024])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tensor_shape = embeddings.shape\n",
    "num_slices, num_rows, num_cols = tensor_shape[0], tensor_shape[1], tensor_shape[2]\n",
    "\n",
    "# Reshape the tensor to a 2D array\n",
    "flat_tensor = tf.reshape(embeddings, (num_slices * num_rows, num_cols))\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "numpy_array = flat_tensor.numpy()\n",
    "\n",
    "# Specify the file path for the CSV file\n",
    "csv_file_path = 'transf_emb.csv'\n",
    "\n",
    "# Save the NumPy array to a CSV file\n",
    "np.savetxt(csv_file_path, numpy_array, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "# Load 34 layer model\n",
    "model, alphabet = esm.pretrained.esm1_t34_670M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Placeholder data (replace this with your actual protein sequences)\n",
    "protein_data = protein_descriptors\n",
    "\n",
    "# Prepare data\n",
    "raw_batch = list(zip(protein_data[\"Target_ID\"], protein_data[\"Target\"]))\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(raw_batch)\n",
    "\n",
    "# Extract per-residue embeddings (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[34])\n",
    "token_embeddings = results[\"representations\"][34]\n",
    "\n",
    "# Generate per-sequence embeddings via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_embeddings = []\n",
    "for i, (_, seq) in enumerate(raw_batch):\n",
    "    sequence_embeddings.append(token_embeddings[i, 1 : len(seq) + 1].mean(0))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
